{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generic to be followed - \n",
    "1. getting the input features and the target \n",
    "2. designing the hidden layers\n",
    "3. sending in the data \n",
    "4. performing the predictions \n",
    "5. figuring out the loss \n",
    "6. SDG and optimizing the parms\n",
    "7. monituring hte loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class ANN_from_scratch():\n",
    "    relu=lambda x: max(0,x)\n",
    "    relu_dash=lambda x: np.where(x > 0, 1, 0)\n",
    "    def __init__(self,features,y_actual):\n",
    "        self.features=features\n",
    "        self.y=y_actual\n",
    "    def ann(self):\n",
    "        in_size=2\n",
    "        hidden=1\n",
    "        output=1\n",
    "\n",
    "        #defining the weights\n",
    "        w1=np.random.randn(in_size, hidden)\n",
    "        b1 = np.zeros((1, hidden))\n",
    "        w2=np.random.randn(hidden,output)\n",
    "        b2=np.zeros((1, output))\n",
    "\n",
    "        # Hyperparameters\n",
    "        learning_rate = 0.01\n",
    "        num_epochs = 10000\n",
    "\n",
    "        #training \n",
    "        for epoch in range(num_epochs):\n",
    "        # Forward pass working on neuron.\n",
    "            Z1 =self.features.reshape(-1, 1) @ w1 + b1\n",
    "            A1 = ANN_from_scratch.relu(Z1)\n",
    "            Z2 = A1 @ W2 + b2\n",
    "            self.y_pred_nn = Z2\n",
    "\n",
    "            loss = np.mean((self.y_pred_nn - self.y.reshape(-1, 1)) ** 2)\n",
    "\n",
    "            #backward pass \n",
    "            dZ2 = self.y_pred_nn - y.reshape(-1, 1) #\n",
    "            dW2 = A1.T @ dZ2 / self.features.shape[0]\n",
    "            db2 = np.mean(dZ2, axis=0, keepdims=True)\n",
    "            \n",
    "            dA1 = dZ2 @ W2.T\n",
    "            dZ1 = dA1 * ANN_from_scratch.relu_dash(Z1)\n",
    "            dW1 = self.features.reshape(-1, 1).T @ dZ1 / self.features.shape[0]\n",
    "            db1 = np.mean(dZ1, axis=0, keepdims=True)\n",
    "             # Update parameters\n",
    "            W1 -= learning_rate * dW1\n",
    "            b1 -= learning_rate * db1\n",
    "            W2 -= learning_rate * dW2\n",
    "            b2 -= learning_rate * db2\n",
    "\n",
    "            # Print loss every 1000 epochs\n",
    "            if epoch % 1000 == 0:\n",
    "                print(f'Epoch {epoch}, Loss: {loss}')\n",
    "        # Plot results\n",
    "        plt.scatter(self.features, self.y, label='Data')\n",
    "        plt.plot(self.features, self.y_pred_nn, color='green', label='Neural Network')\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('y')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.show()    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
